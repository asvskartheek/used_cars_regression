{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (188533, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MINI</td>\n",
       "      <td>Cooper S Base</td>\n",
       "      <td>2007</td>\n",
       "      <td>213000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>A/T</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Gray</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id brand          model  model_year  milage fuel_type  \\\n",
       "0   0  MINI  Cooper S Base        2007  213000  Gasoline   \n",
       "\n",
       "                                         engine transmission ext_col int_col  \\\n",
       "0  172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel          A/T  Yellow    Gray   \n",
       "\n",
       "        accident clean_title  price  \n",
       "0  None reported         Yes   4200  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (125690, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188533</td>\n",
       "      <td>Land</td>\n",
       "      <td>Rover LR2 Base</td>\n",
       "      <td>2015</td>\n",
       "      <td>98000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>6-Speed A/T</td>\n",
       "      <td>White</td>\n",
       "      <td>Beige</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id brand           model  model_year  milage fuel_type  \\\n",
       "0  188533  Land  Rover LR2 Base        2015   98000  Gasoline   \n",
       "\n",
       "                                         engine transmission ext_col int_col  \\\n",
       "0  240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel  6-Speed A/T   White   Beige   \n",
       "\n",
       "        accident clean_title  price  \n",
       "0  None reported         Yes      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (314223, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv(\"data/train.csv\") \n",
    "print(\"Train shape:\", train.shape )\n",
    "TRAIN_LN = len(train)\n",
    "display( train.head(1) )\n",
    "\n",
    "test = pd.read_csv(\"data/test.csv\") \n",
    "test['price'] = 0 # Doing this for common pre-processing steps.\n",
    "print(\"Test shape:\", test.shape )\n",
    "display( test.head(1) )\n",
    "\n",
    "train = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "print(\"Combined shape:\", train.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: ['brand', 'model', 'model_year', 'fuel_type', 'engine', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n",
      "Numerical features: ['milage']\n"
     ]
    }
   ],
   "source": [
    "CATS = [c for c in train.columns if not c in [\"id\",\"price\"] ]\n",
    "NUMS = ['milage']\n",
    "CATS = [c for c in CATS if not c in NUMS]\n",
    "print(\"Categorical features:\", CATS )\n",
    "print(\"Numerical features:\", NUMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STANDARDIZING NUMERICAL FEATURES\n",
      "milage, new_mean=-0.00, new_std=1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"STANDARDIZING NUMERICAL FEATURES\")\n",
    "for c in NUMS:\n",
    "    m = train[c].mean()\n",
    "    s = train[c].std()\n",
    "    train[c] = (train[c]-m)/s\n",
    "    train[c] = train[c].fillna(m)\n",
    "    print(f\"{c}, new_mean={train[c].mean():.2f}, new_std={train[c].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Categorical Features:\n",
      "brand: unique=57, min_freq=0, max_freq=56, rare_count=8\n",
      "model: unique=1898, min_freq=0, max_freq=1897, rare_count=551\n",
      "model_year: unique=36, min_freq=0, max_freq=35, rare_count=4\n",
      "fuel_type: unique=8, min_freq=0, max_freq=7, rare_count=1\n",
      "engine: unique=1118, min_freq=0, max_freq=1117, rare_count=308\n",
      "transmission: unique=52, min_freq=0, max_freq=51, rare_count=8\n",
      "ext_col: unique=319, min_freq=0, max_freq=318, rare_count=99\n",
      "int_col: unique=156, min_freq=0, max_freq=155, rare_count=48\n",
      "accident: unique=3, min_freq=0, max_freq=2, rare_count=0\n",
      "clean_title: unique=2, min_freq=0, max_freq=1, rare_count=0\n"
     ]
    }
   ],
   "source": [
    "cat_feature_sizes = []\n",
    "cat_embedding_sizes = []\n",
    "rare_cat_lists = []\n",
    "MIN_CATEGORY_COUNT = 40\n",
    "\n",
    "print(\"Label Encoding Categorical Features:\")\n",
    "for cat_feature in CATS:\n",
    "    train[cat_feature], _ = train[cat_feature].factorize()\n",
    "    train[cat_feature] -= train[cat_feature].min() # We are doing this to ensure that the encoded values start from 0, ensuring a consistent range for all categorical features.\n",
    "    value_counts = train[cat_feature].value_counts().to_dict()\n",
    "    \n",
    "    # Identify rare categories\n",
    "    rare_cat_lists.append([\n",
    "        value\n",
    "        for value, count in value_counts.items()\n",
    "        if count < MIN_CATEGORY_COUNT\n",
    "    ])\n",
    "    unique_count = train[cat_feature].nunique()\n",
    "    min_freq = train[cat_feature].min()\n",
    "    max_freq = train[cat_feature].max()\n",
    "    rare_count = len(rare_cat_lists[-1])\n",
    "    print(f'{cat_feature}: unique={unique_count}, min_freq={min_freq}, max_freq={max_freq}, rare_count={rare_count}')\n",
    "    \n",
    "    # Adjust category encoding\n",
    "    cat_feature_sizes.append(max_freq + 2)  # +2 for rare category (0) and zero-indexing (1 to max_freq+1). This ensures we have enough space for all categories, including the rare ones grouped together.\n",
    "    cat_embedding_sizes.append(int(np.ceil(np.sqrt(max_freq + 2)))) # TODO: Find a reference for this formula. Got this snippet from https://www.kaggle.com/code/cdeotte/nn-starter-lb-72300-cv-72800\n",
    "    train[cat_feature] += 1\n",
    "    train.loc[train[cat_feature].isin(rare_cat_lists[-1]), cat_feature] = 0 # rare_cat_lists[-1] gives the list of rare categories for the current feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((188533, 13), (125690, 13))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = train.iloc[TRAIN_LN:]\n",
    "train = train.iloc[:TRAIN_LN]\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brand: Test has label encodes = [] which are not in train.\n",
      "model: Test has label encodes = [1898] which are not in train.\n",
      " => 1 rows\n",
      "model_year: Test has label encodes = [36] which are not in train.\n",
      " => 1 rows\n",
      "fuel_type: Test has label encodes = [] which are not in train.\n",
      "engine: Test has label encodes = [1118] which are not in train.\n",
      " => 4 rows\n",
      "transmission: Test has label encodes = [] which are not in train.\n",
      "ext_col: Test has label encodes = [] which are not in train.\n",
      "int_col: Test has label encodes = [] which are not in train.\n",
      "accident: Test has label encodes = [] which are not in train.\n",
      "clean_title: Test has label encodes = [] which are not in train.\n"
     ]
    }
   ],
   "source": [
    "for feature in CATS:\n",
    "    train_categories = train[feature].unique()\n",
    "    test_categories = test[feature].unique()\n",
    "    unseen_categories = np.setdiff1d(test_categories, train_categories)\n",
    "    print(f\"{feature}: Test has label encodes = {unseen_categories} which are not in train.\")\n",
    "    if len(unseen_categories) > 0:\n",
    "        unseen_rows_count = len(test.loc[test[feature].isin(unseen_categories)])\n",
    "        print(f\" => {unseen_rows_count} rows\")\n",
    "    \n",
    "    test.loc[test[feature].isin(unseen_categories), feature] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized price statistics:\n",
      "Train - Mean: -0.0000, Std: 1.0000\n",
      "Test  - Mean: -12.1916, Std: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Apply log transformation to price\n",
    "train['log_price'] = np.log1p(train['price'])\n",
    "test['log_price'] = np.log1p(test['price'])\n",
    "\n",
    "# Standardize the log-transformed price\n",
    "price_mean = train['log_price'].mean()\n",
    "price_std = train['log_price'].std()\n",
    "\n",
    "train['norm_price'] = (train['log_price'] - price_mean) / price_std\n",
    "test['norm_price'] = (test['log_price'] - price_mean) / price_std\n",
    "\n",
    "print(\"Normalized price statistics:\")\n",
    "print(f\"Train - Mean: {train['norm_price'].mean():.4f}, Std: {train['norm_price'].std():.4f}\")\n",
    "print(f\"Test  - Mean: {test['norm_price'].mean():.4f}, Std: {test['norm_price'].std():.4f}\")\n",
    "\n",
    "# Update the target variable\n",
    "target = 'norm_price'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version 2.16.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Embedding\n",
    "from tensorflow.keras.layers import Concatenate, Multiply\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "print('TF Version',tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    DROPOUT_RATE = 0.3\n",
    "\n",
    "    # CATEGORICAL FEATURES\n",
    "    x_input_cats = Input(shape=(len(CATS),))\n",
    "    embs = []\n",
    "    for j in range(len(CATS)):\n",
    "        e = tf.keras.layers.Embedding(cat_feature_sizes[j],cat_embedding_sizes[j])\n",
    "        x = e(x_input_cats[:,j])\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        embs.append(x)\n",
    "        \n",
    "    # NUMERICAL FEATURES\n",
    "    x_input_nums = Input(shape=(len(NUMS),))\n",
    "    \n",
    "    # COMBINE\n",
    "    x = tf.keras.layers.Concatenate(axis=-1)(embs+[x_input_nums]) \n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(DROPOUT_RATE)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(DROPOUT_RATE)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(DROPOUT_RATE)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(1, activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=[x_input_cats,x_input_nums], outputs=x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1 ###\n",
      "#########################\n",
      "Epoch 1/20\n",
      "590/590 - 4s - 7ms/step - loss: 0.1655 - original_price_rmse: 72316.0703 - root_mean_squared_error: 0.6170 - val_loss: 0.1572 - val_original_price_rmse: 67200.9766 - val_root_mean_squared_error: 0.6013 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "590/590 - 3s - 4ms/step - loss: 0.1515 - original_price_rmse: 72219.4062 - root_mean_squared_error: 0.5895 - val_loss: 0.1593 - val_original_price_rmse: 66970.8594 - val_root_mean_squared_error: 0.6050 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "590/590 - 3s - 4ms/step - loss: 0.1483 - original_price_rmse: 71830.2656 - root_mean_squared_error: 0.5827 - val_loss: 0.1530 - val_original_price_rmse: 68021.6016 - val_root_mean_squared_error: 0.5925 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "590/590 - 3s - 4ms/step - loss: 0.1459 - original_price_rmse: 72609.5469 - root_mean_squared_error: 0.5776 - val_loss: 0.1543 - val_original_price_rmse: 67390.8594 - val_root_mean_squared_error: 0.5961 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "590/590 - 3s - 4ms/step - loss: 0.1397 - original_price_rmse: 72140.7578 - root_mean_squared_error: 0.5649 - val_loss: 0.1544 - val_original_price_rmse: 67331.9375 - val_root_mean_squared_error: 0.5965 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "590/590 - 3s - 4ms/step - loss: 0.1382 - original_price_rmse: 72271.8906 - root_mean_squared_error: 0.5617 - val_loss: 0.1542 - val_original_price_rmse: 67431.1016 - val_root_mean_squared_error: 0.5956 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "590/590 - 3s - 5ms/step - loss: 0.1369 - original_price_rmse: 72334.3672 - root_mean_squared_error: 0.5589 - val_loss: 0.1536 - val_original_price_rmse: 67541.1484 - val_root_mean_squared_error: 0.5947 - learning_rate: 1.0000e-05\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      " => Original Price RMSE = 69964.19726126285\n",
      "\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "#########################\n",
      "### Fold 2 ###\n",
      "#########################\n",
      "Epoch 1/20\n",
      "590/590 - 4s - 7ms/step - loss: 0.1661 - original_price_rmse: 71554.6562 - root_mean_squared_error: 0.6181 - val_loss: 0.1620 - val_original_price_rmse: 67648.6719 - val_root_mean_squared_error: 0.6102 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "590/590 - 2s - 4ms/step - loss: 0.1525 - original_price_rmse: 72010.8828 - root_mean_squared_error: 0.5912 - val_loss: 0.1619 - val_original_price_rmse: 67554.8125 - val_root_mean_squared_error: 0.6095 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "590/590 - 3s - 5ms/step - loss: 0.1488 - original_price_rmse: 72202.8594 - root_mean_squared_error: 0.5837 - val_loss: 0.1589 - val_original_price_rmse: 68663.0000 - val_root_mean_squared_error: 0.6015 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "590/590 - 3s - 4ms/step - loss: 0.1469 - original_price_rmse: 72239.7266 - root_mean_squared_error: 0.5800 - val_loss: 0.1556 - val_original_price_rmse: 67935.6875 - val_root_mean_squared_error: 0.5977 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "590/590 - 3s - 5ms/step - loss: 0.1405 - original_price_rmse: 72091.3828 - root_mean_squared_error: 0.5669 - val_loss: 0.1530 - val_original_price_rmse: 68645.5625 - val_root_mean_squared_error: 0.5919 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "590/590 - 3s - 5ms/step - loss: 0.1389 - original_price_rmse: 72124.1328 - root_mean_squared_error: 0.5633 - val_loss: 0.1551 - val_original_price_rmse: 68292.5781 - val_root_mean_squared_error: 0.5961 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "590/590 - 3s - 4ms/step - loss: 0.1379 - original_price_rmse: 72416.0859 - root_mean_squared_error: 0.5613 - val_loss: 0.1531 - val_original_price_rmse: 68551.4844 - val_root_mean_squared_error: 0.5922 - learning_rate: 1.0000e-05\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      " => Original Price RMSE = 70782.85121099054\n",
      "\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "#########################\n",
      "### Fold 3 ###\n",
      "#########################\n",
      "Epoch 1/20\n",
      "590/590 - 3s - 6ms/step - loss: 0.1660 - original_price_rmse: 71339.3047 - root_mean_squared_error: 0.6181 - val_loss: 0.1530 - val_original_price_rmse: 70094.3984 - val_root_mean_squared_error: 0.5936 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "590/590 - 2s - 4ms/step - loss: 0.1521 - original_price_rmse: 71166.6094 - root_mean_squared_error: 0.5906 - val_loss: 0.1595 - val_original_price_rmse: 70130.6641 - val_root_mean_squared_error: 0.6044 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "590/590 - 2s - 4ms/step - loss: 0.1487 - original_price_rmse: 71308.5859 - root_mean_squared_error: 0.5834 - val_loss: 0.1508 - val_original_price_rmse: 70418.2734 - val_root_mean_squared_error: 0.5889 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "590/590 - 2s - 4ms/step - loss: 0.1425 - original_price_rmse: 71862.9453 - root_mean_squared_error: 0.5710 - val_loss: 0.1513 - val_original_price_rmse: 70275.4766 - val_root_mean_squared_error: 0.5893 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "590/590 - 2s - 4ms/step - loss: 0.1408 - original_price_rmse: 71619.6641 - root_mean_squared_error: 0.5674 - val_loss: 0.1516 - val_original_price_rmse: 70203.9609 - val_root_mean_squared_error: 0.5900 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "590/590 - 2s - 4ms/step - loss: 0.1396 - original_price_rmse: 71878.2266 - root_mean_squared_error: 0.5647 - val_loss: 0.1522 - val_original_price_rmse: 70111.2031 - val_root_mean_squared_error: 0.5913 - learning_rate: 1.0000e-05\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      " => Original Price RMSE = 75417.53940223131\n",
      "\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "#########################\n",
      "### Fold 4 ###\n",
      "#########################\n",
      "Epoch 1/20\n",
      "590/590 - 4s - 7ms/step - loss: 0.1665 - original_price_rmse: 70596.4375 - root_mean_squared_error: 0.6192 - val_loss: 0.1529 - val_original_price_rmse: 71981.3906 - val_root_mean_squared_error: 0.5924 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "590/590 - 3s - 5ms/step - loss: 0.1520 - original_price_rmse: 71089.9766 - root_mean_squared_error: 0.5902 - val_loss: 0.1555 - val_original_price_rmse: 71771.1719 - val_root_mean_squared_error: 0.5976 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "590/590 - 2s - 4ms/step - loss: 0.1488 - original_price_rmse: 71332.4062 - root_mean_squared_error: 0.5838 - val_loss: 0.1510 - val_original_price_rmse: 72230.6094 - val_root_mean_squared_error: 0.5894 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "590/590 - 2s - 4ms/step - loss: 0.1467 - original_price_rmse: 70554.9766 - root_mean_squared_error: 0.5794 - val_loss: 0.1512 - val_original_price_rmse: 72230.5781 - val_root_mean_squared_error: 0.5887 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "590/590 - 3s - 4ms/step - loss: 0.1406 - original_price_rmse: 71126.2969 - root_mean_squared_error: 0.5667 - val_loss: 0.1526 - val_original_price_rmse: 72033.1719 - val_root_mean_squared_error: 0.5918 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "590/590 - 3s - 5ms/step - loss: 0.1391 - original_price_rmse: 71362.3906 - root_mean_squared_error: 0.5638 - val_loss: 0.1518 - val_original_price_rmse: 72125.5078 - val_root_mean_squared_error: 0.5905 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "590/590 - 3s - 5ms/step - loss: 0.1378 - original_price_rmse: 71153.9922 - root_mean_squared_error: 0.5609 - val_loss: 0.1520 - val_original_price_rmse: 72090.4609 - val_root_mean_squared_error: 0.5910 - learning_rate: 1.0000e-05\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      " => Original Price RMSE = 78085.46294369872\n",
      "\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "#########################\n",
      "### Fold 5 ###\n",
      "#########################\n",
      "Epoch 1/20\n",
      "590/590 - 5s - 8ms/step - loss: 0.1662 - original_price_rmse: 70310.9531 - root_mean_squared_error: 0.6179 - val_loss: 0.1568 - val_original_price_rmse: 72033.6719 - val_root_mean_squared_error: 0.6023 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "590/590 - 3s - 5ms/step - loss: 0.1523 - original_price_rmse: 70766.7891 - root_mean_squared_error: 0.5901 - val_loss: 0.1564 - val_original_price_rmse: 72020.2266 - val_root_mean_squared_error: 0.6009 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "590/590 - 2s - 4ms/step - loss: 0.1490 - original_price_rmse: 70724.9453 - root_mean_squared_error: 0.5837 - val_loss: 0.1586 - val_original_price_rmse: 71986.0469 - val_root_mean_squared_error: 0.6056 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "590/590 - 3s - 5ms/step - loss: 0.1472 - original_price_rmse: 70556.3047 - root_mean_squared_error: 0.5799 - val_loss: 0.1595 - val_original_price_rmse: 71980.0859 - val_root_mean_squared_error: 0.6076 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "590/590 - 4s - 6ms/step - loss: 0.1450 - original_price_rmse: 70892.3828 - root_mean_squared_error: 0.5754 - val_loss: 0.1585 - val_original_price_rmse: 71893.5156 - val_root_mean_squared_error: 0.6068 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "590/590 - 2s - 4ms/step - loss: 0.1432 - original_price_rmse: 71037.5312 - root_mean_squared_error: 0.5715 - val_loss: 0.1561 - val_original_price_rmse: 71929.7109 - val_root_mean_squared_error: 0.6021 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "590/590 - 2s - 4ms/step - loss: 0.1417 - original_price_rmse: 71412.9375 - root_mean_squared_error: 0.5682 - val_loss: 0.1622 - val_original_price_rmse: 71835.2422 - val_root_mean_squared_error: 0.6129 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "590/590 - 2s - 4ms/step - loss: 0.1400 - original_price_rmse: 71245.8516 - root_mean_squared_error: 0.5648 - val_loss: 0.1544 - val_original_price_rmse: 72273.5547 - val_root_mean_squared_error: 0.5979 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "590/590 - 4s - 7ms/step - loss: 0.1382 - original_price_rmse: 71238.4766 - root_mean_squared_error: 0.5605 - val_loss: 0.1572 - val_original_price_rmse: 71966.8516 - val_root_mean_squared_error: 0.6038 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "590/590 - 3s - 4ms/step - loss: 0.1317 - original_price_rmse: 71425.5234 - root_mean_squared_error: 0.5469 - val_loss: 0.1542 - val_original_price_rmse: 72503.4688 - val_root_mean_squared_error: 0.5971 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "590/590 - 2s - 4ms/step - loss: 0.1300 - original_price_rmse: 71661.5703 - root_mean_squared_error: 0.5430 - val_loss: 0.1562 - val_original_price_rmse: 72290.0781 - val_root_mean_squared_error: 0.6012 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "590/590 - 2s - 4ms/step - loss: 0.1285 - original_price_rmse: 71415.1328 - root_mean_squared_error: 0.5397 - val_loss: 0.1552 - val_original_price_rmse: 72405.8047 - val_root_mean_squared_error: 0.5992 - learning_rate: 1.0000e-05\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      " => Original Price RMSE = 78565.10331561301\n",
      "\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 20\n",
    "NUM_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "EVAL_BATCH_SIZE = 512\n",
    "MODEL_CHECKPOINT_DIR = f\"checkpoints/\"\n",
    "MODEL_CHECKPOINT_FILE = f\"NN_{VERSION}.weights.h5\"\n",
    "TENSORBOARD_LOG_DIR = f\"tensorboard_logs/version_{VERSION}\"\n",
    "\n",
    "kf = KFold(n_splits=NUM_FOLDS, random_state=RANDOM_STATE, shuffle=True)\n",
    "\n",
    "out_of_fold_predictions = np.zeros(len(train))\n",
    "test_predictions = np.zeros(len(test))\n",
    "\n",
    "# Create directory for model checkpoints\n",
    "if not os.path.exists(MODEL_CHECKPOINT_DIR):\n",
    "    os.makedirs(MODEL_CHECKPOINT_DIR)\n",
    "\n",
    "# Create directory for TensorBoard logs\n",
    "if not os.path.exists(TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(TENSORBOARD_LOG_DIR)\n",
    "\n",
    "# Implement inverse_normalize_price function using TensorFlow operations\n",
    "def inverse_normalize_price(normalized_price):\n",
    "    return tf.math.expm1(normalized_price * price_std + price_mean)\n",
    "\n",
    "# Custom RMSE metric for original price\n",
    "@tf.function\n",
    "def original_price_rmse(y_true, y_pred):\n",
    "    y_true_original = inverse_normalize_price(y_true)\n",
    "    y_pred_original = inverse_normalize_price(y_pred)\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true_original - y_pred_original)))\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train), 1):\n",
    "    print(\"#\" * 25)\n",
    "    print(f\"### Fold {fold} ###\")\n",
    "    print(\"#\" * 25)\n",
    "\n",
    "    # Prepare data for current fold\n",
    "    X_train_cats = train.loc[train_index, CATS].values\n",
    "    X_train_nums = train.loc[train_index, NUMS].values\n",
    "    y_train = train.loc[train_index, \"norm_price\"].values\n",
    "    \n",
    "    X_val_cats = train.loc[val_index, CATS].values\n",
    "    X_val_nums = train.loc[val_index, NUMS].values\n",
    "    y_val = train.loc[val_index, \"norm_price\"].values\n",
    "    \n",
    "    X_test_cats = test[CATS].values\n",
    "    X_test_nums = test[NUMS].values\n",
    "    \n",
    "    # Train model\n",
    "    K.clear_session()\n",
    "    model = build_model()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.001), \n",
    "                  loss=tf.keras.losses.Huber(delta=1.0), \n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError(), original_price_rmse])\n",
    "    \n",
    "    # Create TensorBoard callback\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=f\"{TENSORBOARD_LOG_DIR}/fold_{fold}\",\n",
    "        histogram_freq=1,\n",
    "        write_graph=True,\n",
    "        write_images=True,\n",
    "        update_freq='epoch',\n",
    "        profile_batch=0\n",
    "    )\n",
    "    \n",
    "    # Create Early Stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_original_price_rmse',\n",
    "        patience=5,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Create ReduceLROnPlateau callback\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_original_price_rmse',\n",
    "        factor=0.1,\n",
    "        patience=2,\n",
    "        min_lr=1e-6,\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    model.fit([X_train_cats, X_train_nums], y_train, \n",
    "              validation_data=([X_val_cats, X_val_nums], y_val),\n",
    "              callbacks=[reduce_lr, tensorboard_callback, early_stopping],\n",
    "              batch_size=TRAIN_BATCH_SIZE, epochs=EPOCHS, verbose=2)\n",
    "    \n",
    "    # Save model weights\n",
    "    model.save_weights(f'{MODEL_CHECKPOINT_DIR}/{MODEL_CHECKPOINT_FILE}')\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    val_predictions = model.predict([X_val_cats, X_val_nums], verbose=1, batch_size=EVAL_BATCH_SIZE).flatten()\n",
    "    val_predictions_original = inverse_normalize_price(val_predictions).numpy()\n",
    "    y_val_original = inverse_normalize_price(y_val).numpy()\n",
    "    rmse = np.sqrt(np.mean((val_predictions_original - y_val_original)**2))\n",
    "    print(f' => Original Price RMSE = {rmse}\\n')\n",
    "    \n",
    "    # Store out-of-fold predictions\n",
    "    out_of_fold_predictions[val_index] = val_predictions_original\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    fold_test_predictions = model.predict([X_test_cats, X_test_nums], verbose=1, batch_size=EVAL_BATCH_SIZE).flatten()\n",
    "    fold_test_predictions_original = inverse_normalize_price(fold_test_predictions).numpy()\n",
    "    test_predictions += fold_test_predictions_original\n",
    "\n",
    "# Average test predictions across all folds\n",
    "test_predictions /= NUM_FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall CV RSME = 74649.56976201534\n"
     ]
    }
   ],
   "source": [
    "# COMPUTE AND DISPLAY CV RSME SCORE\n",
    "rsme = np.sqrt(np.mean( (out_of_fold_predictions-train.price.values)**2 ))\n",
    "print(\"Overall CV RSME =\",rsme)\n",
    "\n",
    "# SAVE OOF \n",
    "oof_df = train[[\"id\"]].copy()\n",
    "oof_df[\"pred\"] = out_of_fold_predictions\n",
    "oof_df.to_csv(f\"predictions/oof_v{VERSION}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (125690, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188533</td>\n",
       "      <td>17449.484766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188534</td>\n",
       "      <td>54422.836719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188535</td>\n",
       "      <td>44435.767188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188536</td>\n",
       "      <td>23846.071094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188537</td>\n",
       "      <td>30371.865625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         price\n",
       "0  188533  17449.484766\n",
       "1  188534  54422.836719\n",
       "2  188535  44435.767188\n",
       "3  188536  23846.071094\n",
       "4  188537  30371.865625"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(\"data/sample_submission.csv\")\n",
    "sub.price = test_predictions\n",
    "print(\"Submission shape:\",sub.shape)\n",
    "sub.to_csv(f\"predictions/submission_v{VERSION}.csv\",index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
