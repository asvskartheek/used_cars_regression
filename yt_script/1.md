# Video 1 - Description
Kaggle's Used Car Price Prediction Challenge is a regression problem where the goal is to predict the price of used cars based on various features. This is an interesting problem as it has applications in the automotive industry, finance, and even for individual car buyers and sellers.

References:
GitHub Repository: https://github.com/asvskartheek/used_cars_regression
Original Dataset: https://www.kaggle.com/datasets/taeefnajib/used-car-price-prediction-dataset
pandas factorize: https://pandas.pydata.org/docs/reference/api/pandas.factorize.html
NN Starter notebook: https://www.kaggle.com/code/cdeotte/nn-starter-lb-72300-cv-72800



# Video 1 - Script
Solving Kaggle's Used Car Price Prediction Challenge

[Intro animation with title: "Kaggle Playground Series S4E9: Used Car Price Prediction"]

[Show Kaggle competition overview page]

Hello everyone, and welcome to our new series on tackling Kaggle's Playground Series competitions. I'm Kartheek, and today we're diving into the current competition - S4E9: predicting used car prices.

Let's start by taking a look at the competition page. This challenge is part of Kaggle's Playground Series, which provides a great opportunity for data scientists of all levels to practice their regression model development skills and learn new techniques by solving the problem of predicting used car prices.

Our task is to build a model that can predict the price of used cars based on various features. This is an interesting problem as it has applications in the automotive industry, finance, and even for individual car buyers and sellers.

As we can see, all of our submissions are evaluated on the Root Mean Squared Error (RMSE) metric. This is a common metric for regression problems, and we want to minimize this value to get the best possible model. Lower the RMSE, better the model. If you want to know more about RMSE metric, let me know in the comments below.

Now, let's take a look at the data page.

[Show Data page]

The competition provides us with the following files:

1. train.csv - This is our training dataset, including the target variable 'price'.
2. test.csv - This is the test dataset on which we need to make predictions.
3. sample_submission.csv - This file shows the format in which we need to submit our predictions.

The data was generated from a model trained on the used car dataset from cars.com website. The original dataset has only 4009 data points, I will link the original dataset in the description below. Data is generated so that it is a little bit cleaner than the real world data and we will have more data points than just 4000.

[Click on the train.csv file]
Let's take a closer look at the features we have:

- id: A unique identifier for each car listing
- brand: manufacturer of the car
- model: model of the car
- model_year: year the car was manufactured
- milage: total distance the car has been driven
- fuel_type: type of fuel the car uses (e.g., petrol, diesel, electric)
- engine: type of engine
- transmission: type of transmission (e.g., manual, automatic)
- ext_color: exterior color of the car
- int_color: interior color of the car, like dashboard.
- price: The price of the car, this is our target variable

Now that we have a decent understanding of the competition and the type of data we are dealing with, let's start building our first model.


[Switch to GitHub page]

First step for us is to get the data into our local environment. These are the CLI commands to do that, it downloads data using kaggle API, if you don't have kaggle API, you can install using pip install kaggle. Running these commands will get the data in the same strucuture as I did in my repository.

[Show pip install kaggle on the screen]

[Show the first cell output on the screen]

Now let us explore the data, we will be using pandas for data loading and manipulation throughout this series. We can see that we have 188 thousand+ training samples and 125 thousand+ test samples. This is plenty of data for us, so for the first model we will be using neural networks because we are not data poor, and train our neural network model to convergence.

Whenever we look at a dataset, a good practice is to maintain categorical feature columns and numerical feature columns separately, because they will be processed differently. For this dataset, except milage all other features are categorical in nature, some might confuse 'model_year' as a numerical feature, but it is categorical in nature because we don't want our model to learn any order or sequence in the years, it is more of a metadata information.

[Show numerical feature standardization output]

For our numerical feature, 'milage', we're applying standardization. This means we're scaling the values so they have a mean of 0 and a standard deviation of 1. This is a common preprocessing step that helps neural networks learn more effectively. Standardization is particularly beneficial because it ensures that all features contribute equally to the model's learning process, preventing features with larger scales from dominating the training.

[Show categorical feature encoding]

For our categorical features, we're converting the feature into numerical values using label encoding, we do this with factorize function in the pandas library. This method is useful for obtaining a numeric representation of an array of categorical values. For further reference, I will leave a link to the documentation of this function in the description below. Then we are removing rare category values, we are defining them as the categories with less than 40 samples in the dataset. This is a common technique to remove noise in the data and prevent overfitting on outliers. In the end, we will have a new category - RARE, which will be used for all the rare categories in the dataset. Now we have a number of unique values, for each of the categorical features. Let's calculate the appropriate embedding dimension required for each of the categorical features. A common heuristic to determine the embedding dimension is to take the square root of the number of categories. As of now, I could not find a reference for this, if you are aware please comment down below. As soon as I find a reference I will update the video description along with the link, I have taken this heuristic from the NN Starter notebook on Kaggle discussion forum, I will also leave a link to this notebook in the description below.

Once we are done with the above processing, let us double check if there are any new category values in test dataset that is not present in train dataset. Whenever there are data points like this, we will just replace them with RARE category here the numerical value is 0. This is a common and necessary step, otherwise our model will throw an error during the inference as it was never trained on that new category. As you can see, there are a few model names, engine types that we don't have in train dataset, we will replace them with RARE category.

Finally, let's build our neural network model!!

[Show model architecture cell]
Now, let's look at our model architecture. We're using a neural network with separate inputs for categorical and numerical features. The categorical features are embedded, which is a technique that helps the model learn meaningful representations of categories. For each of the categorical features, we have a separate embedding layer. This allows the model to learn different weight matrices for each category in the embedding space. In the end we combine all the embeddings and pass it to the dense layers. We have three dense layers in total, with 256 units each and ReLU activation functions, this are just standard choices, you can experiment with different architectures. Finally we pass it to the output layer which has a single unit and linear activation function, here we will get our final predicted price.

[Show model training setup cell]
We are using 5-fold cross-validation to ensure our model generalizes well. This means we'll train the model 5 times on different subsets of the data and average the results. Here we are will get train and validation data indices for each of the 5 folds, so we are looping through each of the folds and training the model. We're using the Adam optimizer and mean squared error as our loss function. Mean squared error or MSE for short is just the average of the squared differences between the predicted and actual values, it is a common loss function for regression problems.

[Show learning rate scheduler cell]
A common practice in training neural network models is to use a learning rate scheduler to help the model converge effectively. Here we will be training the model for 3 epochs, first 2 epochs our learning rate is 10 to the minus 3, then for the last epoch we will be reducing it to 10 to the minus 4. All of these are standard practices.

If you want to learn more about any of the mentioned things, let me know in the comments below. Like K-fold cross-validation, learning rate schedulers, embedding layers, Adam Optimizer, MSE loss function, etc. Finally let us train the model and see how it performs. Each of the fold's RMSE values are:
  1. 68,019.37
  2. 68,775.68
  3. 74,037.45
  4. 76,533.42
  5. 76,244.09
Resulting in an overall RMSE of 72,813.14.

Let us look at the tensorboard visualizations for the training process.

[Show tensorboard visualizations]
As you can see both the loss and the RMSE is decreasing with each epoch, this is a good sign that our model is learning the data. Remember that RMSE is just the square root of the MSE loss, so it is a measure of the average error of our model, so lower the RMSE, better the model.

[Show submission file cell]
Now let us create the submission file, such that we can submit it to Kaggle and get it evaluated and receive a public score and a rank.

[Switch to Kaggle submission page and ranks]
And there we have it! With a very simple neural network model, we have got a public score of 72,328 and we are at rank 512. This is a decent score, as the rank number 1 model's RMSE is 71,891. We are just within 0.6% away from the top score.

In the next video, let us work on improving the model's performance further and try to get a better score. For this, I would be researching and reading discussion forums and other notebooks, and incorporate their learnings into our model. Our end goal is to be in the top 100 in the leaderboard and today is a decent starting point.

Thank you for watching, and I hope you found this helpful. If you did, please like and subscribe for more machine learning content. See you tomorrow in the next video, on how I am trying to improve the model's performance further.

[Outro animation]