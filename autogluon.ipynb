{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asvs/kartheek_hobby_projects/used_cars_regression/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240920_183007\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.2.0: Wed Nov 15 21:59:33 PST 2023; root:xnu-10002.61.3~2/RELEASE_ARM64_T8112\n",
      "CPU Count:          8\n",
      "Memory Avail:       1.93 GB / 8.00 GB (24.1%)\n",
      "Disk Space Avail:   117.62 GB / 460.43 GB (25.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (188533 samples, 123.87 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240920_183007\"\n",
      "Train Data Rows:    188533\n",
      "Train Data Columns: 12\n",
      "Label Column:       price\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (2954083, 2000, 43878.01618, 78819.52225)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2067.04 MB\n",
      "\tTrain Data (Original)  Memory Usage: 116.69 MB (5.6% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 5.6% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['engine']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 116\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 116 to 76 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t('object', [])       : 8 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t('object', ['text']) : 1 | ['engine']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['engine']\n",
      "\t\t('int', [])                         :  3 | ['id', 'model_year', 'milage']\n",
      "\t\t('int', ['binned', 'text_special']) : 11 | ['engine.char_count', 'engine.word_count', 'engine.capital_ratio', 'engine.lower_ratio', 'engine.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :  1 | ['clean_title']\n",
      "\t\t('int', ['text_ngram'])             : 54 | ['__nlp__.0hp', '__nlp__.0hp 0l', '__nlp__.0hp 0l cylinder', '__nlp__.0hp 0l straight', '__nlp__.0hp 0l v6', ...]\n",
      "\t6.7s = Fit runtime\n",
      "\t12 features in original data used to generate 77 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 28.05 MB (1.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 6.72s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.013260278041509975, Train Rows: 186033, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-103743.3731\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.51s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-109472.4528\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-95312.7934\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.48s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-95068.1917\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.36s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 135 due to low memory. Expected memory usage reduced from 33.1% -> 15.0% of available memory...\n",
      "\t-96324.1712\t = Validation score   (-root_mean_squared_error)\n",
      "\t59.76s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-95836.2011\t = Validation score   (-root_mean_squared_error)\n",
      "\t87.99s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 138 due to low memory. Expected memory usage reduced from 32.42% -> 15.0% of available memory...\n",
      "\t-98321.3653\t = Validation score   (-root_mean_squared_error)\n",
      "\t41.3s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 2: early stopping\n",
      "\t-94713.153\t = Validation score   (-root_mean_squared_error)\n",
      "\t77.59s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-96318.9247\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.35s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-96796.3261\t = Validation score   (-root_mean_squared_error)\n",
      "\t56.37s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-95477.7762\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.562, 'LightGBM': 0.25, 'RandomForestMSE': 0.188}\n",
      "\t-94228.1035\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 345.82s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 26200.4 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240920_183007\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "train_data = TabularDataset('data/train.csv')\n",
    "predictor = TabularPredictor(label='price').fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: data/test.csv | Columns = 12 / 12 | Rows = 125690 -> 125690\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188533</td>\n",
       "      <td>Land</td>\n",
       "      <td>Rover LR2 Base</td>\n",
       "      <td>2015</td>\n",
       "      <td>98000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>6-Speed A/T</td>\n",
       "      <td>White</td>\n",
       "      <td>Beige</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>18968.167969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id brand           model  model_year  milage fuel_type  \\\n",
       "0  188533  Land  Rover LR2 Base        2015   98000  Gasoline   \n",
       "\n",
       "                                         engine transmission ext_col int_col  \\\n",
       "0  240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel  6-Speed A/T   White   Beige   \n",
       "\n",
       "        accident clean_title         price  \n",
       "0  None reported         Yes  18968.167969  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = TabularDataset('data/test.csv')\n",
    "predictor = TabularPredictor.load(\"AutogluonModels/ag-20240920_183007\")\n",
    "predictions = predictor.predict(test_data) # returns a pandas series\n",
    "\n",
    "test_data['price'] = predictions.values\n",
    "display(test_data.head(1))\n",
    "test_data[['id','price']].to_csv(f'predictions/submission_v{VERSION}.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
